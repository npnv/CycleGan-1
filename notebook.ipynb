rt_time":"2020-12-29T10:04:53.884536","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Import Lib"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:04:53.958117Z","iopub.status.busy":"2020-12-29T10:04:53.957315Z","iopub.status.idle":"2020-12-29T10:04:59.047704Z","shell.execute_reply":"2020-12-29T10:04:59.048354Z"},"papermill":{"duration":5.1197,"end_time":"2020-12-29T10:04:59.048586","exception":false,"start_time":"2020-12-29T10:04:53.928886","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.layers import InputSpec, Layer\nfrom tensorflow.keras import Model\nimport os\ntry:\n    from kaggle_datasets import KaggleDatasets\n    REMOTE_FLAG = True\nexcept:\n    print(\"Load Local Dataset\")\n    REMOTE_FLAG = False","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.032827,"end_time":"2020-12-29T10:04:59.113326","exception":false,"start_time":"2020-12-29T10:04:59.080499","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Setup TPU"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:04:59.186836Z","iopub.status.busy":"2020-12-29T10:04:59.186004Z","iopub.status.idle":"2020-12-29T10:04:59.201322Z","shell.execute_reply":"2020-12-29T10:04:59.20261Z"},"papermill":{"duration":0.056681,"end_time":"2020-12-29T10:04:59.202766","exception":false,"start_time":"2020-12-29T10:04:59.146085","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTO = tf.data.experimental.AUTOTUNE\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.034734,"end_time":"2020-12-29T10:04:59.273306","exception":false,"start_time":"2020-12-29T10:04:59.238572","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:04:59.36081Z","iopub.status.busy":"2020-12-29T10:04:59.359761Z","iopub.status.idle":"2020-12-29T10:04:59.395631Z","shell.execute_reply":"2020-12-29T10:04:59.396346Z"},"papermill":{"duration":0.089419,"end_time":"2020-12-29T10:04:59.396552","exception":false,"start_time":"2020-12-29T10:04:59.307133","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"IMAGE_SIZE = [256, 256]\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image\n\ndef load_dataset(filenames):\n    dataset = tf.data.TFRecordDataset(filenames)\n    # print(dataset)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    return dataset\n\n\ndef get_dataset(filenames, augment=None, repeat=True, shuffle=True, batch_size=1):\n    dataset = load_dataset(filenames)\n\n    if augment:\n        dataset = dataset.map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    if repeat:\n        dataset = dataset.repeat(count=1)\n\n    dataset = dataset.concatenate(load_dataset(filenames))\n\n    if shuffle:\n        dataset = dataset.shuffle(1000)\n\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n    return dataset\n\ndef data_augment_2(image):\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n\n    # Apply jitter\n    if p_crop > .5:\n        image = tf.image.resize(image, [286, 286])\n        image = tf.image.random_crop(image, size=[256, 256, 3])\n        if p_crop > .9:\n            image = tf.image.resize(image, [300, 300])\n            image = tf.image.random_crop(image, size=[256, 256, 3])\n\n    # Random rotation\n    if p_rotate > .9:\n        image = tf.image.rot90(image, k=3)  # rotate 270º\n    elif p_rotate > .7:\n        image = tf.image.rot90(image, k=2)  # rotate 180º\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=1)  # rotate 90º\n\n    # Random mirroring\n    if p_spatial > .6:\n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n        if p_spatial > .9:\n            image = tf.image.transpose(image)\n\n    return image","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:04:59.47184Z","iopub.status.busy":"2020-12-29T10:04:59.471015Z","iopub.status.idle":"2020-12-29T10:05:04.17027Z","shell.execute_reply":"2020-12-29T10:05:04.171292Z"},"papermill":{"duration":4.738969,"end_time":"2020-12-29T10:05:04.17152","exception":false,"start_time":"2020-12-29T10:04:59.432551","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"if REMOTE_FLAG:\n    GCS_PATH = KaggleDatasets().get_gcs_path('gan-getting-started')\nelse:\n    GCS_PATH = './gan-getting-started'\nMONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))\nPHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\nmonet_ds = get_dataset(MONET_FILENAMES, augment=data_augment_2, batch_size=1)\nphoto_ds = get_dataset(PHOTO_FILENAMES, augment=data_augment_2, batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.024376,"end_time":"2020-12-29T10:05:04.219904","exception":false,"start_time":"2020-12-29T10:05:04.195528","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Loss"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:04.276054Z","iopub.status.busy":"2020-12-29T10:05:04.275015Z","iopub.status.idle":"2020-12-29T10:05:04.281455Z","shell.execute_reply":"2020-12-29T10:05:04.280957Z"},"papermill":{"duration":0.038473,"end_time":"2020-12-29T10:05:04.281554","exception":false,"start_time":"2020-12-29T10:05:04.243081","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"with strategy.scope():\n    loss_object = keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n\n    # Define loss functions\n    def discriminator_loss(disc_real_output, disc_generated_output):\n        # compare the real image with a matrix of 1. (All Ok)\n        real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n\n        # compare the fake image with a matrix of 0 (All Fake)\n        generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n\n        total_disc_loss = (real_loss + generated_loss) / 2\n\n        return total_disc_loss\n\n\n    def generator_adversarial_loss(generated):\n        return loss_object(tf.ones_like(generated), generated)\n\n\n    def generator_calc_cycle_loss(real_image, cycled_image, param_lambda):\n        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n        return param_lambda * loss1\n\n\n    def generator_identity_loss(real_image, same_image, param_lambda):\n        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n        return param_lambda * 0.5 * loss","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.023953,"end_time":"2020-12-29T10:05:04.328912","exception":false,"start_time":"2020-12-29T10:05:04.304959","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# optimizer of each model"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:04.38475Z","iopub.status.busy":"2020-12-29T10:05:04.384055Z","iopub.status.idle":"2020-12-29T10:05:04.388219Z","shell.execute_reply":"2020-12-29T10:05:04.387631Z"},"papermill":{"duration":0.035824,"end_time":"2020-12-29T10:05:04.388322","exception":false,"start_time":"2020-12-29T10:05:04.352498","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"class MyDynamicLR(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_learning_rate, decay_steps):\n        super().__init__()\n        self.initial_learning_rate = tf.cast(initial_learning_rate, dtype=tf.float32)\n        self.decay_steps = tf.cast(decay_steps, dtype=tf.float32)\n        self.name = name\n        \n    def __call__(self, step):\n        if( step / self.decay_steps < 100 ) return self.initial_learning_rate\n        else {\n            decay_delta = self.initial_learning_rate / 100\n            return self.initial_learning_rate - decay_delta * (step / self.decay_steps - 100)\n        }","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:04.441928Z","iopub.status.busy":"2020-12-29T10:05:04.441231Z","iopub.status.idle":"2020-12-29T10:05:04.444555Z","shell.execute_reply":"2020-12-29T10:05:04.445039Z"},"papermill":{"duration":0.032888,"end_time":"2020-12-29T10:05:04.445161","exception":false,"start_time":"2020-12-29T10:05:04.412273","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"with strategy.scope():\n    generator_monet_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    generator_photo_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    discriminator_monet_optimizer = tf.keras.optimizers.Adam(MyDynamicLR(2e-4, 600), beta_1=0.5)\n    discriminator_photo_optimizer = tf.keras.optimizers.Adam(MyDynamicLR(2e-4, 600), beta_1=0.5)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.024632,"end_time":"2020-12-29T10:05:04.493482","exception":false,"start_time":"2020-12-29T10:05:04.46885","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Build Model"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:04.561904Z","iopub.status.busy":"2020-12-29T10:05:04.551135Z","iopub.status.idle":"2020-12-29T10:05:04.573386Z","shell.execute_reply":"2020-12-29T10:05:04.573881Z"},"papermill":{"duration":0.055024,"end_time":"2020-12-29T10:05:04.574004","exception":false,"start_time":"2020-12-29T10:05:04.51898","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"class CycleGan(keras.Model):\n    def __init__(\n            self,\n            generator_monet,\n            generator_photo,\n            discriminator_monet,\n            discriminator_photo,\n            lambda_cycle=10,\n            lambda_identity=10\n    ):\n        super(CycleGan, self).__init__()\n        self.generator_monet = generator_monet\n        self.generator_photo = generator_photo\n        self.discriminator_monet = discriminator_monet\n        self.discriminator_photo = discriminator_photo\n        self.lambda_cycle = lambda_cycle\n        self.lambda_identity = lambda_identity\n\n    def compile(\n            self,\n            generator_monet_optimizer,\n            generator_photo_optimizer,\n            discriminator_monet_optimizer,\n            discriminator_photo_optimizer,\n            discriminator_loss,\n            generator_adversarial_loss,\n            generator_calc_cycle_loss,\n            generator_identity_loss,\n            metrics\n    ):\n        super(CycleGan, self).compile()\n        self.generator_monet_optimizer = generator_monet_optimizer\n        self.generator_photo_optimizer = generator_photo_optimizer\n        self.discriminator_monet_optimizer = discriminator_monet_optimizer\n        self.discriminator_photo_optimizer = discriminator_photo_optimizer\n        self.discriminator_loss = discriminator_loss\n        self.generator_adversarial_loss = generator_adversarial_loss\n        self.generator_calc_cycle_loss = generator_calc_cycle_loss\n        self.generator_identity_loss = generator_identity_loss\n        self.metrics = metrics\n\n    def train_step(self, batch_data):\n        monet, photo = batch_data\n\n        with tf.GradientTape(persistent=True) as tape:\n            # photo to monet back to photo\n            gen_output_monet_fake = self.generator_monet(photo, training=False)\n            gen_output_photo_cycle = self.generator_photo(gen_output_monet_fake, training=False)\n\n            # monet to photo back to monet\n            gen_output_photo_fake = self.generator_photo(monet, training=False)\n            gen_output_monet_cycle = self.generator_monet(gen_output_photo_fake, training=False)\n\n            # generating itself\n            gen_output_monet_same = self.generator_monet(monet, training=False)\n            gen_output_photo_same = self.generator_photo(photo, training=False)\n\n            # discriminator used to check, inputing real images\n            disc_out_monet_real = self.discriminator_monet(monet, training=False)\n            disc_out_photo_real = self.discriminator_photo(photo, training=False)\n\n            # discriminator used to check, inputing fake images\n            disc_out_monet_fake = self.discriminator_monet(gen_output_monet_fake, training=False)\n            disc_out_photo_fake = self.discriminator_photo(gen_output_photo_fake, training=False)\n\n\n\n            # evaluates generator loss\n            gen_monet_adversarial_loss = self.generator_adversarial_loss(disc_out_monet_fake)\n            gen_photo_adversarial_loss = self.generator_adversarial_loss(disc_out_photo_fake)\n\n            total_cycle_loss = (self.generator_calc_cycle_loss(monet, gen_output_monet_cycle, self.lambda_cycle)\n                                + self.generator_calc_cycle_loss(photo, gen_output_photo_cycle, self.lambda_cycle))\n\n            gen_monet_identity_loss = self.generator_identity_loss(monet, gen_output_monet_same, self.lambda_identity)\n            gen_photo_identity_loss = self.generator_identity_loss(photo, gen_output_photo_same, self.lambda_identity)\n\n            # Total generator loss = adversarial loss + cycle loss + identity loss\n            total_gen_monet_loss = (gen_monet_adversarial_loss + total_cycle_loss + gen_monet_identity_loss)\n            total_gen_photo_loss = (gen_photo_adversarial_loss + total_cycle_loss + gen_photo_identity_loss)\n\n            # evaluates discriminator loss\n            disc_monet_loss = self.discriminator_loss(disc_out_monet_real, disc_out_monet_fake)\n            disc_photo_loss = self.discriminator_loss(disc_out_photo_real, disc_out_photo_fake)\n\n\n        # Calculate the gradients for generator and discriminator\n        gen_monet_gradients = tape.gradient(total_gen_monet_loss,\n                                            self.generator_monet.trainable_variables)\n        gen_photo_gradients = tape.gradient(total_gen_photo_loss,\n                                            self.generator_photo.trainable_variables)\n\n        disc_monet_gradients = tape.gradient(disc_monet_loss,\n                                             self.discriminator_monet.trainable_variables)\n        disc_photo_gradients = tape.gradient(disc_photo_loss,\n                                             self.discriminator_photo.trainable_variables)\n\n        # Apply the gradients to the optimizer\n        self.generator_monet_optimizer.apply_gradients(zip(gen_monet_gradients,\n                                                           self.generator_monet.trainable_variables))\n        self.generator_photo_optimizer.apply_gradients(zip(gen_photo_gradients,\n                                                           self.generator_photo.trainable_variables))\n\n        self.discriminator_monet_optimizer.apply_gradients(zip(disc_monet_gradients,\n                                                               self.discriminator_monet.trainable_variables))\n        self.discriminator_photo_optimizer.apply_gradients(zip(disc_photo_gradients,\n                                                               self.discriminator_photo.trainable_variables))\n\n        return {\n            \"total_gen_monet_loss\": total_gen_monet_loss,\n            \"total_gen_photo_loss\": total_gen_photo_loss,\n            \"disc_monet_loss\": disc_monet_loss,\n            \"disc_photo_loss\": disc_photo_loss\n        }","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.024053,"end_time":"2020-12-29T10:05:04.621687","exception":false,"start_time":"2020-12-29T10:05:04.597634","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Down/Up sample"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:04.682701Z","iopub.status.busy":"2020-12-29T10:05:04.678945Z","iopub.status.idle":"2020-12-29T10:05:04.685953Z","shell.execute_reply":"2020-12-29T10:05:04.68528Z"},"papermill":{"duration":0.039819,"end_time":"2020-12-29T10:05:04.686047","exception":false,"start_time":"2020-12-29T10:05:04.646228","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"#Build the generator preparation\nwith strategy.scope():\n    def downsample(filters, size, apply_instancenorm=True):\n        initializer = tf.random_normal_initializer(0., 0.02)\n\n        result = keras.Sequential()\n        result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n                                 kernel_initializer=initializer, use_bias=not apply_instancenorm ))# when applying Normalization you already have the bias implicit\n        result.add(layers.LeakyReLU())\n        return result\n\n    def upsample(filters, size, apply_dropout=False):\n        initializer = tf.random_normal_initializer(0., 0.02)\n\n        result = keras.Sequential()\n        result.add(layers.Conv2DTranspose(filters, size, strides=2,\n                                          padding='same',\n                                          kernel_initializer=initializer,\n                                          use_bias=False))\n        if apply_dropout:\n            result.add(layers.Dropout(0.5))\n\n        result.add(layers.ReLU())\n        return result","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.02431,"end_time":"2020-12-29T10:05:04.734487","exception":false,"start_time":"2020-12-29T10:05:04.710177","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Resnet Block"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:04.797094Z","iopub.status.busy":"2020-12-29T10:05:04.796161Z","iopub.status.idle":"2020-12-29T10:05:04.799203Z","shell.execute_reply":"2020-12-29T10:05:04.798711Z"},"papermill":{"duration":0.038125,"end_time":"2020-12-29T10:05:04.799292","exception":false,"start_time":"2020-12-29T10:05:04.761167","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"class ReflectionPadding2D(Layer):\n    def __init__(self, padding=(1, 1), **kwargs):\n        self.padding = tuple(padding)\n        self.input_spec = [InputSpec(ndim=4)]\n        super(ReflectionPadding2D, self).__init__(**kwargs)\n\n    def compute_output_shape(self, s):\n        if s[1] == None:\n            return (None, None, None, s[3])\n        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n\n    def call(self, x, mask=None):\n        w_pad, h_pad = self.padding\n        return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n\n    def get_config(self):\n        config = super(ReflectionPadding2D, self).get_config()\n        print(config)\n        return config","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:04.861322Z","iopub.status.busy":"2020-12-29T10:05:04.860417Z","iopub.status.idle":"2020-12-29T10:05:04.863552Z","shell.execute_reply":"2020-12-29T10:05:04.863031Z"},"papermill":{"duration":0.039917,"end_time":"2020-12-29T10:05:04.863648","exception":false,"start_time":"2020-12-29T10:05:04.823731","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"class ResnetBlock(Model):\n\n    def __init__(self, filters, strides=1):\n        super(ResnetBlock, self).__init__()\n        self.filters = filters\n        self.strides = strides\n\n        self.p1 = ReflectionPadding2D()\n        self.c1 = keras.layers.Conv2D(filters, (3, 3), strides=strides, padding='valid', use_bias=False)\n        self.b1 = tfa.layers.InstanceNormalization()\n        self.a1 = keras.layers.Activation('relu')\n\n        self.p2 = ReflectionPadding2D()\n        self.c2 = keras.layers.Conv2D(filters, (3, 3), strides=strides, padding='valid', use_bias=False)\n        self.b2 = tfa.layers.InstanceNormalization()\n\n    def call(self, inputs):\n        residual = inputs  # residual等于输入值本身，即residual=x\n        # 将输入通过卷积、BN层、激活层，计算F(x)\n        x = self.p1(inputs)\n        x = self.c1(x)\n        x = self.b1(x)\n        x = self.a1(x)\n\n        x = self.p2(x)\n        x = self.c2(x)\n        y = self.b2(x) + residual\n        return y\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.023783,"end_time":"2020-12-29T10:05:04.911977","exception":false,"start_time":"2020-12-29T10:05:04.888194","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Generator"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:04.984085Z","iopub.status.busy":"2020-12-29T10:05:04.9789Z","iopub.status.idle":"2020-12-29T10:05:04.990074Z","shell.execute_reply":"2020-12-29T10:05:04.989546Z"},"papermill":{"duration":0.054121,"end_time":"2020-12-29T10:05:04.990179","exception":false,"start_time":"2020-12-29T10:05:04.936058","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"class Generator(Model):\n\n    def __init__(self):  # block_list表示每个block有几个卷积层\n        \n        super(Generator, self).__init__()\n        self.num_blocks = 9\n        \n        self.p1 = ReflectionPadding2D((3, 3))\n        self.c1 = keras.layers.Conv2D(64, (7, 7), strides=1, padding='valid', use_bias=False)\n        self.b1 = tfa.layers.InstanceNormalization()\n        self.a1 = keras.layers.Activation('relu')\n        \n        # Two down sampling layers\n        self.c2 = keras.layers.Conv2D(128, (3, 3), strides=2, padding='same', use_bias=False)\n        self.b2 = tfa.layers.InstanceNormalization()\n        self.a2 = keras.layers.Activation('relu')\n        \n        self.c3 = keras.layers.Conv2D(256, (3, 3), strides=2, padding='same', use_bias=False)\n        self.b3 = tfa.layers.InstanceNormalization()\n        self.a3 = keras.layers.Activation('relu')\n        \n        # Calc Blocks\n        self.blocks = keras.models.Sequential()\n        # 构建ResNet网络结构\n        for block_id in range(self.num_blocks):  # 第几个resnet block\n            block = ResnetBlock(256)\n            self.blocks.add(block)  # 将构建好的block加入resnet\n            \n        # Two up Sampling layers\n        self.t4 = keras.layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', output_padding=1)\n        self.b4 = tfa.layers.InstanceNormalization()\n        self.a4 = keras.layers.Activation('relu')\n        \n        self.t5 = keras.layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', output_padding=1)\n        self.b5 = tfa.layers.InstanceNormalization()\n        self.a5 = keras.layers.Activation('relu')\n                \n        self.p6 = ReflectionPadding2D((3, 3))\n        self.c6 = keras.layers.Conv2D(3, (7, 7), strides=1, padding='valid', use_bias=False)\n        self.a6 = keras.layers.Activation('tanh')\n        \n\n    def call(self, inputs):\n        x = self.p1(inputs)\n        x = self.c1(x)\n        x = self.b1(x)\n        x = self.a1(x)\n        \n        x = self.c2(x)\n        x = self.b2(x)\n        x = self.a2(x)\n        \n        x = self.c3(x)\n        x = self.b3(x)\n        x = self.a3(x)\n        \n        x = self.blocks(x)\n        \n        x = self.t4(x)\n        x = self.b4(x)\n        x = self.a4(x)\n        \n        x = self.t5(x)\n        x = self.b5(x)\n        x = self.a5(x)\n        \n        x = self.p6(x)\n        x = self.c6(x)\n        y = self.a6(x)\n        return y","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.024811,"end_time":"2020-12-29T10:05:05.039406","exception":false,"start_time":"2020-12-29T10:05:05.014595","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Discriminator"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:05.100481Z","iopub.status.busy":"2020-12-29T10:05:05.099558Z","iopub.status.idle":"2020-12-29T10:05:05.102596Z","shell.execute_reply":"2020-12-29T10:05:05.101948Z"},"papermill":{"duration":0.039124,"end_time":"2020-12-29T10:05:05.102696","exception":false,"start_time":"2020-12-29T10:05:05.063572","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"# Build the discriminator\ndef Discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n\n    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n\n    down1 = downsample(64, 4, False)(inp) # (bs, 128, 128, 64)\n    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n\n    zero_pad1 = layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n    conv = layers.Conv2D(512, 4, strides=1,\n                         kernel_initializer=initializer,\n                         use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n\n    leaky_relu = layers.LeakyReLU()(conv)\n\n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n\n    last = layers.Conv2D(1,\n                         kernel_size = 4,\n                         strides=1,\n                         kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n\n    return tf.keras.Model(inputs=inp, outputs=last)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.024827,"end_time":"2020-12-29T10:05:05.152518","exception":false,"start_time":"2020-12-29T10:05:05.127691","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Train"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:05.207475Z","iopub.status.busy":"2020-12-29T10:05:05.206824Z","iopub.status.idle":"2020-12-29T10:05:05.925862Z","shell.execute_reply":"2020-12-29T10:05:05.925311Z"},"papermill":{"duration":0.748477,"end_time":"2020-12-29T10:05:05.925976","exception":false,"start_time":"2020-12-29T10:05:05.177499","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"with strategy.scope():\n    #Create Generator and Discriminator\n    generator_monet = Generator() # transforms photos to Monet-esque paintings\n    generator_photo = Generator() # transforms Monet paintings to be more like photos\n    discriminator_monet = Discriminator() # differentiates real Monet paintings and generated Monet paintings\n    discriminator_photo = Discriminator() # differentiates real photos and generated photos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_lr_metric(optimizer):\n    def lr(y_true, y_pred):\n        return optimizer.lr\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:05.993582Z","iopub.status.busy":"2020-12-29T10:05:05.984515Z","iopub.status.idle":"2020-12-29T10:05:06.004043Z","shell.execute_reply":"2020-12-29T10:05:06.003257Z"},"papermill":{"duration":0.052327,"end_time":"2020-12-29T10:05:06.004144","exception":false,"start_time":"2020-12-29T10:05:05.951817","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"with strategy.scope():\n    cycle_gan_model = CycleGan(\n        generator_monet, generator_photo, discriminator_monet, discriminator_photo\n    )\n\n    cycle_gan_model.compile(\n            generator_monet_optimizer = generator_monet_optimizer,\n            generator_photo_optimizer = generator_photo_optimizer,\n            discriminator_monet_optimizer = discriminator_monet_optimizer,\n            discriminator_photo_optimizer = discriminator_photo_optimizer,\n            discriminator_loss = discriminator_loss,\n            generator_adversarial_loss = generator_adversarial_loss,\n            generator_calc_cycle_loss = generator_calc_cycle_loss,\n            generator_identity_loss = generator_identity_loss\n            metrics = [get_lr_metrics]\n        )","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.02517,"end_time":"2020-12-29T10:05:06.054472","exception":false,"start_time":"2020-12-29T10:05:06.029302","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## checkpoints"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:06.111063Z","iopub.status.busy":"2020-12-29T10:05:06.110389Z","iopub.status.idle":"2020-12-29T10:05:06.816464Z","shell.execute_reply":"2020-12-29T10:05:06.815938Z"},"papermill":{"duration":0.736806,"end_time":"2020-12-29T10:05:06.81658","exception":false,"start_time":"2020-12-29T10:05:06.079774","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"!mkdir ../checkpoint","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:06.875586Z","iopub.status.busy":"2020-12-29T10:05:06.874934Z","iopub.status.idle":"2020-12-29T10:05:06.878632Z","shell.execute_reply":"2020-12-29T10:05:06.879174Z"},"papermill":{"duration":0.035977,"end_time":"2020-12-29T10:05:06.879324","exception":false,"start_time":"2020-12-29T10:05:06.843347","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"if REMOTE_FLAG:\n    checkpoint_save_path = \"/kaggle/working/checkpoint/CycleGAN.ckpt\"\nelse:\n    checkpoint_save_path = \"./checkpoint/CycleGAN.ckpt\"\nif os.path.exists(checkpoint_save_path + '.index'):\n    print('-------------load the model-----------------')\n    model.load_weights(checkpoint_save_path)\n\ncp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n                                                 save_weights_only=True,\n                                                 save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# epoch"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scheduler(epoch, lr):\n  if epoch < 100:\n    return lr\n  else:\n    return lr - lr / (200 - epoch)\n    \nepoch_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.024871,"end_time":"2020-12-29T10:05:06.929211","exception":false,"start_time":"2020-12-29T10:05:06.90434","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## fit"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T10:05:06.986148Z","iopub.status.busy":"2020-12-29T10:05:06.98522Z","iopub.status.idle":"2020-12-29T13:39:04.599374Z","shell.execute_reply":"2020-12-29T13:39:04.598807Z"},"papermill":{"duration":12837.645075,"end_time":"2020-12-29T13:39:04.599538","exception":false,"start_time":"2020-12-29T10:05:06.954463","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"cycle_gan_model.fit(\n    tf.data.Dataset.zip((monet_ds, photo_ds)),\n    epochs=50,\n    callbacks=[cp_callback, epoch_callback]\n)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":11.508801,"end_time":"2020-12-29T13:39:28.299626","exception":false,"start_time":"2020-12-29T13:39:16.790825","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Plot"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T13:39:50.929994Z","iopub.status.busy":"2020-12-29T13:39:50.92891Z","iopub.status.idle":"2020-12-29T13:39:55.251168Z","shell.execute_reply":"2020-12-29T13:39:55.250662Z"},"papermill":{"duration":15.956425,"end_time":"2020-12-29T13:39:55.251268","exception":false,"start_time":"2020-12-29T13:39:39.294843","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"# Plot\n_, ax = plt.subplots(5, 2, figsize=(12, 12))\nfor i, img in enumerate(photo_ds.take(5)):\n    prediction = generator_monet(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    ax[i, 0].imshow(img)\n    ax[i, 1].imshow(prediction)\n    ax[i, 0].set_title(\"Input Photo\")\n    ax[i, 1].set_title(\"Monet-esque\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":11.517349,"end_time":"2020-12-29T13:40:17.829747","exception":false,"start_time":"2020-12-29T13:40:06.312398","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# SAVE"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T13:40:40.495284Z","iopub.status.busy":"2020-12-29T13:40:40.493694Z","iopub.status.idle":"2020-12-29T13:40:40.495989Z","shell.execute_reply":"2020-12-29T13:40:40.496491Z"},"papermill":{"duration":11.005125,"end_time":"2020-12-29T13:40:40.496618","exception":false,"start_time":"2020-12-29T13:40:29.491493","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"# import PIL\n# ! mkdir ../images\n# i = 1\n# for img in photo_ds:\n#     prediction = monet_generator(img, training=False)[0].numpy()\n#     prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n#     im = PIL.Image.fromarray(prediction)\n#     im.save(\"../images/\" + str(i) + \".jpg\")\n#     i += 1\n    \n# import shutil\n# shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-29T13:41:03.152285Z","iopub.status.busy":"2020-12-29T13:41:03.15018Z","iopub.status.idle":"2020-12-29T13:41:03.155331Z","shell.execute_reply":"2020-12-29T13:41:03.15583Z"},"papermill":{"duration":11.214885,"end_time":"2020-12-29T13:41:03.155957","exception":false,"start_time":"2020-12-29T13:40:51.941072","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"import shutil\nshutil.make_archive(\"/kaggle/working/checkpoint\", 'zip', \"/kaggle/checkpoint\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}